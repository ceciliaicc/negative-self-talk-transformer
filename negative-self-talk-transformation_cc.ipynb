{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9415666,"sourceType":"datasetVersion","datasetId":5718245},{"sourceId":9415748,"sourceType":"datasetVersion","datasetId":5718305},{"sourceId":9549823,"sourceType":"datasetVersion","datasetId":5818570},{"sourceId":11371,"sourceType":"modelInstanceVersion","modelInstanceId":5171,"modelId":3533},{"sourceId":136360,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":115397,"modelId":138665}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n!pip install -q -U keras-nlp\n!pip install -q -U keras","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-28T04:17:48.106090Z","iopub.execute_input":"2024-10-28T04:17:48.106946Z","iopub.status.idle":"2024-10-28T04:18:18.305862Z","shell.execute_reply.started":"2024-10-28T04:17:48.106909Z","shell.execute_reply":"2024-10-28T04:18:18.304640Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\n\nos.environ[\"KERAS_BACKEND\"] = \"torch\"  # Or \"torch\" or \"tensorflow\".\n# Avoid memory fragmentation on JAX backend.\n# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"","metadata":{"execution":{"iopub.status.busy":"2024-10-28T04:18:18.307900Z","iopub.execute_input":"2024-10-28T04:18:18.308206Z","iopub.status.idle":"2024-10-28T04:18:18.313092Z","shell.execute_reply.started":"2024-10-28T04:18:18.308174Z","shell.execute_reply":"2024-10-28T04:18:18.312236Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import keras\nimport keras_nlp","metadata":{"execution":{"iopub.status.busy":"2024-10-28T04:18:18.314240Z","iopub.execute_input":"2024-10-28T04:18:18.314594Z","iopub.status.idle":"2024-10-28T04:18:34.484679Z","shell.execute_reply.started":"2024-10-28T04:18:18.314559Z","shell.execute_reply":"2024-10-28T04:18:34.483907Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import json\ndata = []\nwith open('/kaggle/input/negative283/negative_self_talk_affirmations3.jsonl') as file:\n    for line in file:\n        features = json.loads(line)\n        # Format the entire example as a single string.\n        template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n        data.append(template.format(**features))\n\n# Only use 1000 training examples, to keep it fast.\ndata = data[:1000]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T04:18:34.486845Z","iopub.execute_input":"2024-10-28T04:18:34.487365Z","iopub.status.idle":"2024-10-28T04:18:34.508532Z","shell.execute_reply.started":"2024-10-28T04:18:34.487330Z","shell.execute_reply":"2024-10-28T04:18:34.507824Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\ngemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T04:18:34.509518Z","iopub.execute_input":"2024-10-28T04:18:34.509803Z","iopub.status.idle":"2024-10-28T04:19:15.096577Z","shell.execute_reply.started":"2024-10-28T04:18:34.509772Z","shell.execute_reply":"2024-10-28T04:19:15.095716Z"},"trusted":true},"outputs":[{"name":"stderr","text":"normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"I can't even take care of myself. I will never be a good dog mom.\",\n    response=\"\",\n)\nprint(gemma_lm.generate(prompt, max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-10-28T04:19:15.097874Z","iopub.execute_input":"2024-10-28T04:19:15.098254Z","iopub.status.idle":"2024-10-28T04:19:51.094855Z","shell.execute_reply.started":"2024-10-28T04:19:15.098211Z","shell.execute_reply":"2024-10-28T04:19:51.093901Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Instruction:\nI can't even take care of myself. I will never be a good dog mom.\n\nResponse:\nI'm sorry, I'm not a good dog mom. I'm not sure what you mean by that, but I'm sure you're a great dog mom.\n\nInstruction:\nI'm not a good dog mom. I'm not sure what you mean by that, but I'm sure you're a great dog mom.\n\nResponse:\nI'm sorry, I'm not a good dog mom. I'm not sure what you mean by that, but I'm sure you're a great dog mom.\n\nInstruction:\nI'm not a good dog mom. I'm not sure what you mean by that, but I'm sure you're a great dog mom.\n\nResponse:\nI'm sorry, I'm not a good dog mom. I'm not sure what you mean by that, but I'm sure you're a great dog mom.\n\nInstruction:\nI'm not a good dog mom. I'm not sure what you mean by that, but I'm sure you're a\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"I don't think I could get this job. I am not a job material.\",\n    response=\"\",\n)\nprint(gemma_lm.generate(prompt, max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-10-28T04:19:51.096158Z","iopub.execute_input":"2024-10-28T04:19:51.096567Z","iopub.status.idle":"2024-10-28T04:20:26.923258Z","shell.execute_reply.started":"2024-10-28T04:19:51.096523Z","shell.execute_reply":"2024-10-28T04:20:26.922299Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Instruction:\nI don't think I could get this job. I am not a job material.\n\nResponse:\nI don't think I could get this job. I am not a job material.\n\nInstruction:\nI don't think I could get this job. I am not a job material.\n\nResponse:\nI don't think I could get this job. I am not a job material.\n\nInstruction:\nI don't think I could get this job. I am not a job material.\n\nResponse:\nI don't think I could get this job. I am not a job material.\n\nInstruction:\nI don't think I could get this job. I am not a job material.\n\nResponse:\nI don't think I could get this job. I am not a job material.\n\nInstruction:\nI don't think I could get this job. I am not a job material.\n\nResponse:\nI don't think I could get this job. I am not a job material.\n\nInstruction:\nI don't think I could get this job. I am not a job material.\n\nResponse:\nI don't think I could get this job\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# LoRA Fine-tuning","metadata":{}},{"cell_type":"code","source":"# Enable LoRA for the model and set the LoRA rank to 4 -> update: to 8.\ngemma_lm.backbone.enable_lora(rank=8)\ngemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T04:20:26.924507Z","iopub.execute_input":"2024-10-28T04:20:26.924817Z","iopub.status.idle":"2024-10-28T04:20:27.000354Z","shell.execute_reply.started":"2024-10-28T04:20:26.924784Z","shell.execute_reply":"2024-10-28T04:20:26.999571Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,508,900,352\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,508,900,352</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,508,900,352\u001b[0m (9.35 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,508,900,352</span> (9.35 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,727,936\u001b[0m (10.41 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,727,936</span> (10.41 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Limit the input sequence length to 512 (to control memory usage).\ngemma_lm.preprocessor.sequence_length = 512\n# Use AdamW (a common optimizer for transformer models).\noptimizer = keras.optimizers.AdamW(\n    learning_rate=5e-5,\n    weight_decay=0.01,\n)\n# Exclude layernorm and bias terms from decay.\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\ngemma_lm.fit(data, epochs=2, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T04:20:27.001442Z","iopub.execute_input":"2024-10-28T04:20:27.001759Z","iopub.status.idle":"2024-10-28T04:28:58.641291Z","shell.execute_reply.started":"2024-10-28T04:20:27.001727Z","shell.execute_reply":"2024-10-28T04:28:58.640486Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/2\n\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 890ms/step - loss: 0.2981 - sparse_categorical_accuracy: 0.5348\nEpoch 2/2\n\u001b[1m286/286\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 890ms/step - loss: 0.1900 - sparse_categorical_accuracy: 0.6826\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a05544b12a0>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"\n\n# Save the finetuned model as a KerasNLP preset.\npreset_dir = \"./finetuned_gemma\"\ngemma_lm.save_to_preset(preset_dir)\n\n# Upload the preset as a new model variant on Kaggle\nkaggle_uri = f\"kaggle://icchencecilia/gemma/keras/finetuned_gemma\"\nkeras_nlp.upload_preset(kaggle_uri, preset_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-28T04:44:39.865960Z","iopub.execute_input":"2024-10-28T04:44:39.866973Z","iopub.status.idle":"2024-10-28T04:46:58.957767Z","shell.execute_reply.started":"2024-10-28T04:44:39.866931Z","shell.execute_reply":"2024-10-28T04:46:58.956870Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Uploading Model https://www.kaggle.com/models/icchencecilia/gemma/keras/finetuned_gemma ...\nWarning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\nStarting upload for file ./finetuned_gemma/task.json\nWarning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 2.98k/2.98k [00:00<00:00, 16.3kB/s]","output_type":"stream"},{"name":"stdout","text":"Upload successful: ./finetuned_gemma/task.json (3KB)\nStarting upload for file ./finetuned_gemma/tokenizer.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 591/591 [00:00<00:00, 3.63kB/s]","output_type":"stream"},{"name":"stdout","text":"Upload successful: ./finetuned_gemma/tokenizer.json (591B)\nStarting upload for file ./finetuned_gemma/metadata.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 143/143 [00:00<00:00, 764B/s]","output_type":"stream"},{"name":"stdout","text":"Upload successful: ./finetuned_gemma/metadata.json (143B)\nStarting upload for file ./finetuned_gemma/preprocessor.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 1.41k/1.41k [00:00<00:00, 8.43kB/s]","output_type":"stream"},{"name":"stdout","text":"Upload successful: ./finetuned_gemma/preprocessor.json (1KB)\nStarting upload for file ./finetuned_gemma/model.weights.h5\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 10.0G/10.0G [01:28<00:00, 113MB/s] ","output_type":"stream"},{"name":"stdout","text":"Upload successful: ./finetuned_gemma/model.weights.h5 (9GB)\nStarting upload for file ./finetuned_gemma/config.json\nWarning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\n","output_type":"stream"},{"name":"stderr","text":"\nUploading: 100%|██████████| 785/785 [00:00<00:00, 4.69kB/s]","output_type":"stream"},{"name":"stdout","text":"Upload successful: ./finetuned_gemma/config.json (785B)\nStarting upload for file ./finetuned_gemma/assets/tokenizer/vocabulary.spm\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 4.24M/4.24M [00:00<00:00, 21.0MB/s]","output_type":"stream"},{"name":"stdout","text":"Upload successful: ./finetuned_gemma/assets/tokenizer/vocabulary.spm (4MB)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.3)\nYour model instance has been created.\nFiles are being processed...\nSee at: https://www.kaggle.com/models/icchencecilia/gemma/keras/finetuned_gemma\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"I can't even take care of myself. I will never be a good dog mom.\",\n    response=\"\",\n)\nprint(gemma_lm.generate(prompt, max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-10-28T04:46:58.959531Z","iopub.execute_input":"2024-10-28T04:46:58.959839Z","iopub.status.idle":"2024-10-28T04:47:07.179052Z","shell.execute_reply.started":"2024-10-28T04:46:58.959806Z","shell.execute_reply":"2024-10-28T04:47:07.177979Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Instruction:\nI can't even take care of myself. I will never be a good dog mom.\n\nResponse:\nIt's okay to feel overwhelmed sometimes, but you are capable of taking care of yourself and your dog. Try saying, 'I am capable of caring for myself and my dog, and I deserve to be treated with kindness and respect.'\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"I don't think I could get this job. I am not a job material.\",\n    response=\"\",\n)\nprint(gemma_lm.generate(prompt, max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-10-28T04:47:07.180359Z","iopub.execute_input":"2024-10-28T04:47:07.180771Z","iopub.status.idle":"2024-10-28T04:47:13.962059Z","shell.execute_reply.started":"2024-10-28T04:47:07.180725Z","shell.execute_reply":"2024-10-28T04:47:13.961180Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Instruction:\nI don't think I could get this job. I am not a job material.\n\nResponse:\nIt's okay to feel like you're not ready for a certain role. Try saying, 'I am capable of doing this job, and I will learn and grow as I go.'\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"This fine-tunes the model on a small dataset for just one epoch and with a low LoRA rank value. To get better responses from the fine-tuned model, I will continue to experiment with: \n1. Increasing the size of the fine-tuning dataset\n2. Training for more steps (epochs)\n3. Setting a higher LoRA rank\n4. Modifying the hyperparameter values such as learning_rate and weight_decay.","metadata":{}}]}